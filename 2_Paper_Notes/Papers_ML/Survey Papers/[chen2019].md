# A variable neighborhood search algorithm with reinforcement learning for a real-life periodic vehicle routing problem with time windows and open routes

## Metadata
- **Link to PDF**: [[[chen2019]_A_variable_neighborhood_search_algorithm_with_reinforcement_learning_for_a_real-life_periodic_vehicle_routing_problem_with_time_windows_and_open_routes.pdf]]
- **Tags**:
  - #ML-ReinforcementLearning  
  - #HybridLocalSearchRL  
  - #ML-AssistedLocalSearch  
  - #LocalSearchHeuristics  
  - #DeterministicVRP  
  - #LargeScaleVRP  
  - #OpenVRP  
  - #MultiVehicleRouting  
  - #TimeWindowConstraints  
  - #PeriodicVehicleRouting  
- **Relevant**: true  
- **Fit Score**: 10  
- **State of the Art (SoA) Concepts**:
  - Reinforcement learning-based operator selection (adaptive operator selection)
  - Open periodic VRP with time windows
  - Variable Neighborhood Search (VNS) metaheuristic
  - Feasibility-driven local search with sampling
  - Real-life large-scale container transportation scheduling
- **Performance Evaluation**: yes
- **Performance Evaluation Framework**: Real-life Ningbo Port data + artificially generated data

## Abstract
"Based on a real-life container transport problem, a model of Open Periodic Vehicle Routing Problem with Time Windows (OPVRPTW) is proposed in this paper. In a wide planning horizon, which is divided into a number of shifts, a fixed number of trucks are scheduled to complete container transportation tasks between terminals subject to time constraints. In this problem, the routes traveled by trucks are open, as returning to the starting depot is not required in every single shift but every two shifts.
Our study shows that it is unrealistic to address this large scale and nonlinearly constrained problem with exact search methods. A Reinforcement Learning Based Variable Neighbourhood Search algorithm (VNS-RLS) is developed for OPVRPTW. The initial solution is constructed with an urgency level-based insertion heuristic, while different insertion selection strategies are compared. In the local search phase of VNS-RLS, reinforcement learning is used to guide the search, adjusting the probabilities of operators being invoked adaptively according to the change of generated solutions' feasibility and quality. In addition, the impact of sampling neighbourhood space in single solution-based algorithms is also investigated. Three indicators are designed in the proposed Sampling module to set the starting configuration of local search.
Experiment results on different sizes of real and artificial benchmark instances show that, the proposed Sampling scheme and feasibility indicator decrease the infeasible rate during the search. However, Sampling's contribution to solution quality improvement is not significant in this single solution-based algorithm. Comparing to the exact search and two state-of-the-art algorithms, VNS-RLS produces promising results."

## Summary
- **Paper Focus & VRP Variant**  
  - Proposes a new model called Open Periodic Vehicle Routing Problem with Time Windows (OPVRPTW), inspired by a real-life container transport scenario at a major port.  
  - Combines periodic scheduling (multiple consecutive shifts) with time windows and open routes (trucks do not necessarily return to the depot after each shift but rather every two shifts).

- **Motivation & Problem Setting**  
  - Addresses a large-scale container transportation problem where each shift has a 12-hour window.  
  - Ports operate with a fixed-size fleet (up to 100 trucks), each shift possibly transferring tasks to subsequent shifts (day → night).  
  - The goal is to minimize total empty-travel distance, effectively maximizing the “heavy-loaded distance rate.”  
  - The authors note that exact methods (CPLEX) struggle with memory/time on even modest problem sizes due to the nonlinear constraints and very large solution space.

- **Machine Learning & Methodology**  
  - Employs a **Reinforcement Learning (RL)** framework to guide a **Variable Neighborhood Search (VNS)**:
    - The VNS is adapted with eight different neighborhood operators at various perturbation levels (intra-route, intra-shift, and inter-shift moves).
    - A learning scheme adjusts operator selection probabilities using reward/penalty signals based on solution quality improvements and feasibility.
  - **Sampling Module**: Before local search, the algorithm samples each operator from the current solution to estimate feasibility rates and average improvement potential, then sets initial weights for each operator accordingly.
  - **Feasibility Indicator**: Penalizes operators that produce infeasible solutions, reducing the chance that operators causing frequent time window violations continue to dominate the search.

- **Constructive Heuristic (Initial Solution)**  
  - A specialized insertion heuristic groups tasks into “mandatory” (due soon) and “optional.”  
  - Compares three insertion strategies (Greedy, First-Insertion, One-Route) for both mandatory and optional tasks:
    - **Greedy** tends to yield better initial solution quality but costs more computation time.
    - **First-Insertion** is faster but riskier (it might miss feasible insertions, requiring more trucks).
    - **One-Route** balances quality and speed by focusing insertion checks within a single route in each iteration.

- **Key Findings & Experiments**  
  - Tested on real Ningbo Port data (4–8 shifts, up to 1000+ tasks) and on artificial datasets (balanced/unbalanced, tight/loose time windows).  
  - **Exact solver** (CPLEX) fails or takes over 24 hours on many instances, often exhausting memory.  
  - **Proposed VNS-RLS** outperforms standard VNS variants and existing PVRP-based methods (RVNS, FVNS) in terms of solution quality (heavy-loaded distance rate), while reducing infeasible attempts significantly.  
  - **Sampling** meaningfully decreases infeasible solutions encountered during search, though it adds limited improvement to the final objective in single-solution-based approaches.  
  - The best combination for large-scale instances is often using “One-Route + Greedy” for constructing mandatory and optional tasks, balancing feasibility with route tightness.

- **Strengths & Contributions**  
  - Successfully integrates RL for dynamic operator selection in a large-scale, multi-shift VRP with time windows.  
  - Demonstrates how adaptive weight updates and feasibility-driven measures can steer the search away from poorly constrained neighborhoods.  
  - Validates the approach on real port operations data, showing practical viability.

- **Limitations & Future Directions**  
  - Sampling only captures local neighborhood information and may not significantly boost final solution quality in single-solution-based search.  
  - The approach focuses on a single-objective (minimize empty distance), whereas real-life might include multiple objectives (emissions, route balancing).  
  - Authors propose investigating more aggressive diversification operators (e.g., Large Neighborhood Search) and extended constraints (e.g., carbon emission, driver regulations) as future work.

- **Relevance for Deterministic VRP & ML**  
  - The paper is highly relevant to deterministic VRPs, using a **reinforcement learning** mechanism for adaptively guiding a local search.  
  - A valuable case study on how to incorporate feasibility checks and sampling in a resource-intensive VRP variant.  
  - Offers a real-life problem perspective, bridging academic research with large-scale port logistics practice.  