# Attention, Learn to Solve Routing Problems!

## Metadata
- **Link to PDF**: [[[kool2019]_Attention,_Learn_to_Solve_Routing_Problems!.pdf]]
- **Tags**:  
	#RL-PolicyGradient
	#PointerNetworks
	#AttentionMechanismAM
	#TransformerModels
	#NeuralCombinatorialOptimization
	#TSP
	#CVRP
	#SDVRP
	#HeuristicOrExactBlends
	#Generalization
	#ORtoolsPackage
	#LKH3Solver
	#Orienteering
	#PCTSP
- **Relevant**: true  
- **Fit Score**:   
- **State of the Art (SoA) Concepts**:  
  - Attention-based neural architectures for routing problems (Transformer-style encoder-decoder)
  - REINFORCE policy gradient with self-critical (rollout) baseline
  - Comparisons with Pointer Networks and state-of-the-art solvers (LKH, OR-Tools)
  - Applications to TSP, CVRP, SDVRP, Orienteering Problem, and PCTSP
- **Performance Evaluation**: yes  
- **Performance Evaluation Framework**: Custom random instance generation for each problem variant (TSP, CVRP, SDVRP, OP, PCTSP); Comparisons against Gurobi, LKH3, OR-Tools, and classical heuristics

## Abstract
“The recently presented idea to learn heuristics for combinatorial optimization problems is promising as it can save costly development. However, to push this idea towards practical implementation, we need better models and better ways of training. We contribute in both directions: we propose a model based on attention layers with benefits over the Pointer Network and we show how to train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which we find is more efficient than using a value function. We significantly improve over recent learned heuristics for the Travelling Salesman Problem (TSP), getting close to optimal results for problems up to 100 nodes. With the same hyperparameters, we learn strong heuristics for two variants of the Vehicle Routing Problem (VRP), the Orienteering Problem (OP) and (a stochastic variant of) the Prize Collecting TSP (PCTSP), outperforming a wide range of baselines and getting results close to highly optimized and specialized algorithms.”

## Summary
- **Core Idea & Motivation**
  - Proposes an attention-based neural network (inspired by the Transformer) to learn heuristics for routing problems.
  - Aims to produce competitive or near-optimal solutions without hand-engineered rules.
  - Builds on the Pointer Network framework but replaces recurrent encoders with multi-head self-attention for improved scalability and invariance to input order.

- **ML Technique**
  - Uses a policy gradient (REINFORCE) approach with a self-critical baseline. 
  - The baseline is a deterministic greedy rollout from the policy itself, updated periodically for stability.
  - This method reduces variance in gradient estimates and helps the model surpass the performance of purely learned or purely hand-designed heuristics.

- **VRP Variants & Scope**
  - Addresses the deterministic TSP, CVRP, SDVRP, Orienteering Problem (OP), and Prize Collecting TSP (PCTSP).
  - Also extends to a stochastic PCTSP variant, but the main proof of concept remains on deterministic instances of various routing problems.
  - Demonstrates a single set of hyperparameters can yield effective results across these diverse routing tasks.

- **Methodology & Model Architecture**
  - Encoder: Multi-head attention layers (similar to the Transformer) produce node embeddings that capture rich contextual information.
  - Decoder: At each step, a context embedding (including the last visited node and first node) attends to all nodes to generate probabilities of choosing the next node in the route.
  - Masking ensures no node is visited twice (or capacity constraints are met), and so on.
  - Training data is generated on the fly from random distributions of problem instances, allowing the model to generalize over a broad range of graph instances.

- **Key Experimental Results**
  - **TSP**: Achieves near-optimal performance (within 0.3-0.4% of optimal) on TSP-20, TSP-50, and TSP-100, outperforming previous learned methods.
  - **CVRP & SDVRP**: Outperforms classical insertion heuristics and prior RL-based works (e.g., Nazari et al.). Approaches the performance of LKH3 on mid-sized instances.
  - **Orienteering & PCTSP**: Performs competitively against specialized or state-of-the-art solvers; close to specialized genetic algorithms and strong local search heuristics while running faster.
  - Also compares favorably to OR-Tools in construction or limited-search modes on many problem settings.

- **Strengths & Contributions**
  - Demonstrates that attention-based, graph-invariant encoding is more efficient than recurrence-based models (e.g., Pointer Networks with LSTMs).
  - Introduces a simple but powerful rollout baseline, which accelerates and stabilizes policy gradient training.
  - Provides a flexible template that can be adapted to multiple deterministic routing problems without major changes.

- **Limitations & Notes**
  - The largest benchmark size tested is up to 100 nodes; scaling to thousands of nodes remains a challenge.
  - Certain advanced feasibility constraints (time windows, complex capacity rules) are not deeply explored.
  - The authors highlight that while the approach can handle some constraints via masking, more intricate constraints might require additional logic or backtracking.

- **Relevance to Deterministic VRP Research**
  - Central to the thesis scope: attention-based deep RL for deterministic TSP/VRP.
  - Offers a strong baseline for comparing learned heuristics vs. classical methods, bridging ML and OR approaches.
  - The method’s generalizability and consistent performance across multiple VRP variants make it highly relevant to a survey of ML-based VRP strategies.