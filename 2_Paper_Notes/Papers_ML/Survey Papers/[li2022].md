# Heterogeneous Attentions for Solving Pickup and Delivery Problem via Deep Reinforcement Learning

## Metadata
- **Link to PDF**: [[[li2022]_Heterogeneous_attentions_for_solving_pickup_and_delivery_problem_via_deep_reinforcement_learning.pdf]]
- **Tags**:  
  #ML-ReinforcementLearning  
  #RL-PolicyGradient  
  #RL-ActorCritic  
  #MDP  
  #AttentionMechanismAM  
  #TransformerModels  
  #NeuralCombinatorialOptimization  
  #PDP  
  #DeterministicVRP  
  #ORtoolsPackage  
  #CplexSolver  
- **Relevant**: true  
- **Fit Score**: 10  
- **State of the Art (SoA) Concepts**:
  - Heterogeneous attention mechanisms integrated into a transformer-like encoder-decoder.
  - Actor-Critic RL framework modeling the problem as an MDP.
  - Empirical comparison against classical solvers (CPLEX, OR-Tools) and heuristic methods.
  - Pointer-network/Transformer-based neural combinatorial optimization.  
- **Performance Evaluation**: yes  
- **Performance Evaluation Framework**: custom randomly generated PDP instances (various sizes and distributions).

## Abstract
“Recently, there is an emerging trend to apply deep reinforcement learning to solve the vehicle routing problem (VRP), where a learnt policy governs the selection of next node for visiting. However, existing methods could not handle well the pairing and precedence relationships in the pickup and delivery problem (PDP), which is a representative variant of VRP. To address this challenging issue, we leverage a novel neural network integrated with a heterogeneous attention mechanism to empower the policy in deep reinforcement learning to automatically select the nodes. In particular, the heterogeneous attention mechanism specifically prescribes attentions for each role of the nodes while taking into account the precedence constraint, i.e., the pickup node must precede the pairing delivery node. Further integrated with a masking scheme, the learnt policy is expected to find higher-quality solutions for solving PDP. Extensive experimental results show that our method outperforms the state-of-the-art heuristic and deep learning model, respectively, and generalizes well to different distributions and problem sizes.”

## Summary
- **Problem & Context**  
  - The paper focuses on the Pickup and Delivery Problem (PDP), where each request consists of a pickup node and a corresponding delivery node. A single vehicle must visit every pickup-delivery pair while respecting precedence (pickup before delivery). The objective is to minimize total travel time.
  - PDP is a well-known variant of the VRP but is more challenging than, for example, the classic CVRP, due to pairing and precedence constraints.

- **Key Contribution**  
  - Proposes a **deep reinforcement learning (DRL)** model with a **transformer-like encoder-decoder** architecture to handle PDP specifically.  
  - Introduces a **heterogeneous attention mechanism** that differentiates attentions based on node roles (pickup vs. delivery) and pair relationships. This aims to capture intrinsic precedence constraints more effectively than a single uniform attention layer.
  - Integrates a **masking scheme** ensuring the policy never selects a delivery node before its corresponding pickup node.

- **Methodology**  
  - **Modeling as MDP**: The partial route is the state, and the next node selection is the action. The reward is the negative travel time.  
  - **Encoder**: Uses multiple attention layers (inspired by Transformers). Uniquely, seven types of attention are introduced to capture heterogeneous interactions among pickup-delivery pairs, pickup-to-pickup, delivery-to-delivery, etc.  
  - **Decoder**: Similar to pointer networks or attention-based decoders, generates probabilities of selecting each valid node at each step. A masking mechanism excludes invalid or already visited nodes, enforcing feasibility.  
  - **Training**: Adopts an Actor-Critic (roll-out) reinforcement learning approach, with the critic providing a baseline to reduce variance in policy gradient updates. Trained on synthetic PDP instances with uniformly distributed coordinates.  

- **Experiments & Results**  
  - **Comparison Methods**: Benchmarked against CPLEX (exact solver), OR-Tools, Simulated Annealing, Variable Neighborhood Search, and a baseline DRL approach (“AM”) that uses a simpler attention mechanism.  
  - **Problem Sizes**: PDP instances with 21, 41, 81, and 121 nodes (including depot).  
  - **Key Findings**:  
    1. The heterogeneous attention model consistently outperforms classical heuristics (VNS, SA, OR-Tools) in solution quality while running in significantly less time than exact methods.  
    2. Even the greedy (single-sample) decoding strategy of the proposed DRL produces better results than the simpler “AM” approach, particularly under pairing/precedence constraints.  
    3. By sampling multiple solutions from the policy (e.g., 128 or 12800 samples), further improvement is achieved with only a modest increase in computation time.  
    4. The trained policy generalizes effectively to (a) larger instance sizes than those seen during training, and (b) different node distributions (e.g., Gaussian).  

- **Strengths**  
  - Demonstrates an effective way to incorporate pairing and precedence constraints into a DRL model for VRPs via specialized attentions.  
  - Achieves strong generalization across problem sizes and distributions.  
  - Outperforms standard solvers and heuristics on runtime/quality trade-offs for large-scale PDP.

- **Limitations & Future Directions**  
  - Investigates only a single-vehicle PDP with unlimited capacity; does not explore multi-vehicle or capacity constraints.  
  - Uses synthetic datasets rather than classical benchmark sets (e.g., Solomon for time windows).  
  - The proposed approach can be extended to more complex VRP variants such as time windows or dynamic arrivals, but those aspects are left for future work.  

- **Relevance to Deterministic VRP Research**  
  - The paper contributes a specialized DRL architecture addressing a deterministic VRP sub-problem (PDP), making it highly relevant to deterministic VRP solution strategies.  
  - Illustrates that careful attention design is crucial for capturing the additional structure introduced by precedence requirements in VRP variants.  
  - Supports the broader trend of neural combinatorial optimization in VRPs through advanced attention-based encoders and policy gradient training.  