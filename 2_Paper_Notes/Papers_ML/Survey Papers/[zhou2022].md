# Adaptive Gradient Descent Enabled Ant Colony Optimization for Routing Problems

## Metadata
- **Link to PDF**: [[[zhou2022]_Adaptive_gradient_descent_enabled_ant_colony_optimization_for_routing_problems.pdf]]
- **Tags**:
  - #AdaptiveAntColony
  - #AntColonySystem
  - #RL-PolicyGradient
  - #DeterministicVRP
  - #TSP
  - #CVRP
  - #ML-Hybrid
  - #ParameterTuning
  - #ParallelImplementation
  - #HybridLocalSearchRL
- **Relevant**: true  
- **Fit Score**: 9  
- **State of the Art (SoA) Concepts**:
  - Adaptive gradient-based parameter update for ant colony optimization
  - Reinforcement learning interpretation of ACO (policy gradient)
  - Deterministic routing: TSP and CVRP
  - Parallel implementations of ACO
- **Performance Evaluation**: yes  
- **Performance Evaluation Framework**: TSPLIB and CVRPLIB  

## Abstract
“The design of Ant Colony Optimization (ACO) has been inspired by the foraging behavior of ant colonies. ACO is one of the most widely used metaheuristic algorithms applicable to various optimization problems. Nevertheless, the deficiency of ACO is early maturity and slow convergence, usually leading to dissatisfactory performance. In this research, a new type of ACO is proposed with an innovative adaptive learning mechanism is devised (the algorithm is called ADACO). In the paper, first, the ACO algorithm for Traveling Salesman Problem (TSP) is modeled in the framework of reinforcement learning (RL) and learns a best policy by stochastic gradient descent (SGD). Then, an adaptive gradient descent strategy, which can exploit the update history of per-dimensional pheromones to achieve intelligent convergence, is integrated into the ACO algorithm as ADACO. A parallel computation process is implemented in the process to expedite computational efficiency. Finally, through case studies in TSP and Capacitated Vehicle Routing Problem (CVRP), ADACO is validated. ADACO is trialed on various sizes of TSP and CVRP instances and compared with other state-of-the-art algorithms. Results show that ADACO is competitive in terms of accuracy (better in most cases), stability (statistically significant) and adaptability (support various types of problems). The results also elucidate that the algorithm maintains good computational efficiency owing to its parallel implementation. It can be concluded that ADACO is effectively applicable to routing problems with good performance.”

## Summary
- Proposes an **ACO variant** called ADACO that integrates **adaptive gradient descent (SGD)** techniques to improve convergence and avoid premature stagnation.
- Models **ACO** as a **policy gradient** scheme in **reinforcement learning (RL)**: 
  - The pheromone matrix is treated as learnable parameters.
  - Policy = transition probabilities; Reward = pheromone updates based on route quality.
- Describes how **stochastic gradient descent** can be adapted so each edge’s pheromone value undergoes dimension-specific updates. This allows:
  - Exploiting historical gradient information.
  - Adjusting learning rates across different dimensions (edges).
  - Overcoming the rigid, uniform evaporation factor in classical ACO.
- Integrates an **Adadelta-like** parameter update step, bounding pheromone values (max-min) for stability. 
- Implements **parallel computation** to retain a time complexity on par with standard ACO but benefiting from dimension-wise updates.
- Focuses on **TSP** as the main testbed; also extends approach to **CVRP** by “transforming” CVRP into a TSP format (duplicating depot nodes, applying capacity constraints in the solution construction). 
- Shows **experimental results** on TSPLIB and CVRPLIB:
  - Outperforms baseline ACO algorithms (e.g. MMAS, ACS) in solution quality and stability for TSP and CVRP.
  - Demonstrates that adaptive gradient-based updating can yield better exploration-exploitation trade-offs than static evaporation rates.
- Benchmarks on large TSP (up to 4461 cities), asymmetric TSP, and various CVRP instances confirm:
  - Competitive or superior performance vs. classical ACO variants and some high-level heuristics (ILS).
  - Statistically significant improvements in many cases (Wilcoxon tests).
- Concludes that **ADACO** can be extended to other hard combinatorial routing problems with minimal overhead; the adaptive scheme aids in dealing with diverse instances without extensive parameter tuning.
- Relevance to thesis:
  - Demonstrates an **ML-assisted (reinforcement learning) approach** to a **deterministic VRP** (TSP, CVRP).
  - Illustrates synergy of classic metaheuristics (ACO) with **SGD-based adaptation** to improve solutions and reduce parameter sensitivity.
  - Provides parallelizable, robust method for large-scale deterministic routing.