# RBG: Hierarchically Solving Large-Scale Routing Problems in Logistic Systems via Reinforcement Learning

## Metadata
- **Link to PDF**: [[[zong2022]__RBG-Hierarchically_solving_large-scale_routing_problems_in_logistic_systems_via_reinforcement_learning.pdf]]
- **Tags**:
  - #RL-PolicyGradient
  - #HierarchicalReinforcementLearning
  - #AttentionMechanismAM
  - #CVRP
  - #CVRPTW
  - #PDP
  - #ML-AssistedHeuristics
  - #HeuristicOrExactBlends
  - #HybridLocalSearchRL
  - #LargeScaleVRP
  - #RealWorldData
- **Relevant**: true  
- **Fit Score**: 9  
- **State of the Art (SoA) Concepts**:
  - Hierarchical reinforcement learning structure (rewriter + generator)
  - Divide-and-conquer approach for large-scale CVRP
  - Hybrid of RL with heuristics (LKH/HGS) or neural attention-based solvers
  - Extensions to CVRPTW and pickup-and-delivery scenarios
- **Performance Evaluation**: yes
- **Performance Evaluation Framework**: Custom synthetic data and real-world operational data (not a standard public benchmark)

## Abstract
“The large-scale vehicle routing problems (VRPs) are defined based on the classical VRPs with thousands of customers. It is an important optimization problem in modern logistic systems, since efficiently obtaining high-quality solutions can greatly reduce operation expenses as well as improve customer satisfaction. Most existing algorithms, including traditional non-learning heuristics and learning-based methods, only perform well on small-scale instances with usually no more than hundreds of customers. In this paper we present a novel Rewriting-by-Generating (RBG) framework which solves large-scale VRPs hierarchically. RBG consists of a rewriter agent that refines the customer division globally and an elementary generator to infer regional solutions locally. It is also flexible with multiple CVRP variant problems and could be continuously evolved with more up-to-date generator designs. We conduct extensive experiments on both synthetic and real-world data to demonstrate the effectiveness and efficiency of our proposed RBG framework. It outperforms HGS, one of the best heuristic method for CVRPs and also shortens the inference time. Online evaluation is also conducted on a deployed express platform in Guangdong, China, where RBG shows advantages to other alternative built-in algorithms.”

## Summary
- **Problem & Motivation**
  - Addresses the challenge of solving large-scale Capacitated Vehicle Routing Problems (CVRPs) with thousands of customers.
  - Highlights inefficiencies of both traditional heuristics (e.g., LKH3, HGS) and RL-based methods on very large instances.
  - Aims to combine hierarchical partitioning (divide-and-conquer) with a reinforcement learning approach that can handle large problem sizes more efficiently than existing methods.

- **Core Idea & Methodology**
  - Proposes a two-level hierarchical approach called **Rewriting-by-Generating (RBG)**:
    1. **Generator**: Solves local CVRPs within smaller regions (hyper-regions), either using a trained neural model (e.g., attention-based) or a standard heuristic solver (e.g., LKH, HGS).
    2. **Rewriter**: A reinforcement learning agent that iteratively merges or partitions these regions to improve the overall solution.  
  - **Key Mechanism**:
    - Start with an initial clustering of customers (e.g., via k-means incorporating depot location and polar distance).
    - Solve each small cluster using the chosen “generator.”
    - **Rewriting** step merges two adjacent sub-regions into a hyper-region and re-solves it. If the updated solution is better, it replaces the previous sub-solutions.
    - Re-partitioning is done on a route-level basis; the rewriter chooses which sub-regions to merge based on learned representations (using route embeddings and an LSTM for feature extraction).
    - The action-selection for region merging is trained via a policy gradient (REINFORCE) using an improvement in total route distance as the reward signal.

- **VRP Variants Covered**
  - Focus on **Capacitated VRP (CVRP)** for the main evaluation.
  - Demonstrates adaptability to **CVRP with Time Windows (CVRPTW)** and **CVRP with Mixed Delivery and Pickup (CVRPMDP)** by substituting the local solver with a variant-capable method (LKH in the paper’s demonstration).

- **Machine Learning Techniques**
  - **Hierarchical Reinforcement Learning** structure:
    - “High-level” rewriter agent that learns how to combine (merge) and re-split clusters.
    - “Low-level” generator that either uses:
      - A neural **Attention Model** (transformer-like approach) to produce routes end-to-end, or
      - A classical heuristic solver (LKH3, HGS) to find near-optimal solutions for the smaller sub-instance.
  - **Policy Gradient** optimization (REINFORCE) for the rewriter agent.  
  - Region (cluster) embeddings built with an LSTM to encode the local routes, enabling the rewriter to pick region-pairs to merge.

- **Key Findings / Results**
  - **Improved solution quality** on large-scale CVRP instances (up to 2000 customers) compared to strong baselines, including LKH3, HGS, and other RL-based methods like L2D.
  - **Significant speedup** in inference time:
    - Achieves solutions of similar or superior quality to LKH3/HGS but in less time, as the large problem is decomposed into multiple small subproblems that the generator can solve quickly.
  - Demonstrates that combining RL-based rewriting with a reliable local solver yields especially strong improvements as instance size grows (the advantage gap vs. pure heuristics widens with increasing problem scale).
  - Maintains **robust performance** across different data distributions (random, clustered, real-world city data).
  - Achieves good generalization to practical variants like CVRPTW and pickup-and-delivery, indicating flexibility in real logistics contexts.

- **Strengths**
  - Successfully addresses **large-scale** VRPs, beyond typical RL-based research that often focuses on up to 100 or 200 customers.
  - Hierarchical approach that can incorporate **any** local solver (heuristic or neural), ensuring easy extensibility to new VRP variants.
  - Thorough empirical evaluation on synthetic (random) data and a real operational dataset from a deployed logistics platform in Guangdong, China.
  - Online deployment suggests genuine industrial viability, with time-efficient route recomputation when new demands appear.

- **Limitations & Gaps**
  - Uses custom clustering heuristics and relies on an initial K-means step, which might limit performance if the data distribution is significantly different or if outlier patterns exist.
  - Although it generalizes to time windows and mixed pickup-delivery, still tested primarily with capacity constraints and standard VRP assumptions; might need specialized modifications for more complex real-world constraints.
  - The RL rewriter’s performance depends on hyperparameters (e.g., cluster size, rollout steps), requiring tuning and possibly domain expertise for best results.

- **Relevance for Deterministic VRP Research**
  - Directly addresses deterministic CVRP in large-scale settings; no stochastic or dynamic modeling is introduced.
  - Provides a blueprint for **hybrid ML + OR** solutions that can be extended to a variety of deterministic routing variants.
  - Showcases that reinforcement learning methods can be scalable if augmented with a region-partitioning technique instead of naive end-to-end route generation for thousands of customers.

- **Conclusion / Impact**
  - Demonstrates a promising hierarchical RL-based approach for large-scale deterministic VRPs, balancing solution quality and computational time.
  - Advocates synergy between deep learning methods (attention-based small-scale solvers) and classical heuristics (LKH/HGS) under an RL-driven region decomposition strategy.
  - Highlights potential for robust real-world application, as evidenced by online deployment outcomes and efficiency gains.