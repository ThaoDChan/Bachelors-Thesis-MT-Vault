# Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning

## Metadata
- **Link to PDF**: [[[ma2020]_Combinatorial_Optimization_by_Graph_Pointer_Networks_and_Hierarchical_Reinforcement_Learning.pdf]]
- **Tags**:
  - #ML-ReinforcementLearning  
  - #RL-PolicyGradient  
  - #PointerNetworks  
  - #GraphNeuralNetworks  
  - #AttentionMechanismAM  
  - #NeuralCombinatorialOptimization  
  - #TSP  
  - #TSPTW  
  - #ML-AssistedHeuristics  
  - #LargeScaleVRP  
- **Relevant**: true
- **Fit Score**: 9
- **State of the Art (SoA) Concepts**:
  - Hierarchical reinforcement learning  
  - Graph-based neural encoders (Graph Neural Networks)  
  - Pointer networks for route construction  
  - Policy gradient method  
  - TSP with time windows (deterministic variant)
- **Performance Evaluation**: yes
- **Performance Evaluation Framework**: Custom random TSP datasets (scaling up to TSP1000), TSPLIB for real-world TSP instances


## Abstract
“In this work, we introduce Graph Pointer Networks (GPNs) trained using reinforcement learning (RL) for tackling the traveling salesman problem (TSP). GPNs build upon Pointer Networks by introducing a graph embedding layer on the input, which captures relationships between nodes. Furthermore, to approximate solutions to constrained combinatorial optimization problems such as the TSP with time windows, we train hierarchical GPNs (HGPNs) using RL, which learns a hierarchical policy to find an optimal city permutation under constraints. Each layer of the hierarchy is designed with a separate reward function, resulting in stable training. Our results demonstrate that GPNs trained on small-scale TSP50/100 problems generalize well to larger-scale TSP500/1000 problems, with shorter tour lengths and faster computational times. We verify that for constrained TSP problems such as the TSP with time windows, the feasible solutions found via hierarchical RL training outperform previous baselines. In the spirit of reproducible research we make our data, models, and code publicly available.”


## Summary
- **Problem & Motivation**
  - Addresses the classical Traveling Salesman Problem (TSP) and extends it to a constrained variant, TSP with time windows (TSPTW).  
  - Emphasizes the challenge of solving large-scale TSP instances (up to 1000 nodes) and dealing with additional constraints efficiently.  
  - Motivated by the success of pointer networks in small-scale combinatorial optimization and by the potential of graph neural networks (GNNs) to capture pairwise dependencies among nodes.

- **Core Contributions**
  - **Graph Pointer Network (GPN)**:  
    - Combines a Pointer Network architecture with a graph embedding layer, enabling the model to incorporate node-to-node relationships.  
    - Uses both point context (for smaller TSP) and “vector context” (pairwise offsets between the current city and all others) to enhance generalization.
  - **Hierarchical Reinforcement Learning (HRL)**:  
    - Proposes a two-layer (or multi-layer) hierarchical RL approach, where each layer learns different aspects of the constrained TSP.  
    - The lower layer focuses on maintaining feasibility under time-window constraints; the upper layer minimizes tour length.  
    - Introduces a latent variable passed between layers, effectively creating a prior distribution over feasible solutions.

- **Methodology**
  - **Architecture**:
    1. An encoder with LSTM-based point encoding plus a multi-layer GNN-based embedding of the entire set of nodes.  
    2. An attention-based decoder producing a probability distribution over the next city.  
    3. In hierarchical setups, each layer’s pointer vector is combined to refine the predicted routes.
  - **Training**:
    - Uses policy gradient (REINFORCE) with a “central self-critic” baseline.  
    - Trains on randomly generated TSP20 or TSP50 data (depending on the experiment), then tests on larger instances to check out-of-distribution generalization.  
    - For TSPTW, employs a layer-wise approach: first train the lower layer to ensure feasibility (minimize time-window violations), then fix it and train the higher layer to optimize total route length.

- **Experiments & Results**
  - **Small-Scale TSP (20 & 50 nodes)**:
    - GPN performs comparably to or better than pointer networks and s2v-DQN, though it slightly trails specialized attention models in terms of solution quality.  
    - Shows faster convergence than pointer networks due to graph embeddings.
  - **Large-Scale TSP (100–1000 nodes)**:
    - A single GPN model trained on TSP50 generalizes up to TSP1000 effectively, significantly outperforming standard pointer networks on these larger instances.  
    - Post-processing with a 2-opt local search yields solution quality on par with s2v-DQN and other heuristics in less computation time.
  - **TSP with Time Windows (TSPTW)**:
    - Demonstrates the hierarchical GPN (HGPN) approach yields more feasible solutions (up to 100% feasibility) and lower total route cost compared to single-layer GPN or baselines like OR-Tools.  
    - Sampling from the learned policy further improves solutions, especially under complex time-window constraints.

- **Strengths**
  - Establishes that incorporating GNN-based embeddings captures global structural information, leading to improved generalization.  
  - Hierarchical policy structure stabilizes training for constrained problems (TSPTW) by separating feasibility and cost minimization.  
  - Demonstrates robust performance on instances an order of magnitude larger than the training set size.

- **Weaknesses & Limitations**
  - Although the hierarchical approach improves feasibility for TSPTW, the method can still require tuning (e.g., hyperparameters for penalty factors).  
  - Does not always outperform specialized classical solvers (e.g., LKH) for standard TSP; rather, it aims at scalability and quick approximate solutions.  
  - The feasibility approach relies on a two-step training procedure, adding implementation complexity compared to single-layer RL methods.

- **Relevance & Impact for Deterministic VRP**
  - Highly relevant for designing scalable ML-based solvers for deterministic routing problems, where constraints (like time windows) must be rigorously enforced.  
  - Demonstrates that hierarchical RL can address route feasibility and cost optimization simultaneously, a principle potentially extendable to other VRP variants (e.g., CVRP with capacity constraints).  
  - Contributes to bridging the gap between purely learned heuristics and classical solvers by showing synergy with local search (2-opt) for final improvements.