# Learning to Iteratively Solve Routing Problems with Dual-Aspect Collaborative Transformer

## Metadata
- **Link to PDF**: [[[ma2022]_Learning_to_iteratively_solve_routing_problems_with_dualaspect_collaborative_transformer.pdf]]
- **Tags**:
  - #ML-ReinforcementLearning
  - #RL-PolicyGradient
  - #RL-ActorCritic
  - #ProximalPolicyOptimization
  - #TransformerModels
  - #NeuralCombinatorialOptimization
  - #ML-AssistedLocalSearch
  - #LocalSearchHeuristics
  - #TSP
  - #CVRP
  - #PerformanceComparisons
- **Relevant**: true  
- **Fit Score**: 10  
- **State of the Art (SoA) Concepts**:
  - Dual-aspect collaborative attention mechanism for VRP
  - Cyclic positional encoding (CPE) for better sequence representation
  - Iterative solution improvement via RL policy and local search (2-opt)
  - Proximal Policy Optimization (PPO) training
  - Tests on TSP and CVRP with standard benchmarks (TSPLIB, CVRPLIB)
- **Performance Evaluation**: yes
- **Performance Evaluation Framework**: TSPLIB, CVRPLIB, random TSP/CVRP instances

## Abstract
“Recently, Transformer has become a prevailing deep architecture for solving vehicle routing problems (VRPs). However, it is less effective in learning improvement models for VRP because its positional encoding (PE) method is not suitable in representing VRP solutions. This paper presents a novel Dual-Aspect Collaborative Transformer (DACT) to learn embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. Moreover, the positional features are embedded through a novel cyclic positional encoding (CPE) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions (i.e., cyclic sequences). We train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. We apply DACT to solve the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP). Results show that our DACT outperforms existing Transformer based improvement models, and exhibits much better generalization performance across different problem sizes on synthetic and benchmark instances, respectively.”

## Summary
- **Context and Motivation**
  - The paper addresses the challenge of learning iterative improvement heuristics for deterministic VRPs (focusing on TSP and CVRP).
  - It observes that the standard Transformer-based models exhibit shortcomings when embedding positional information for cyclical routing solutions.
  - Positional encoding (PE) as used in NLP tasks may introduce noise and fail to capture the circular nature of vehicle routing tours.

- **Core Contribution**
  - Proposes a “Dual-Aspect Collaborative Transformer” (DACT) architecture that splits the embedding streams into node feature embeddings and positional feature embeddings (rather than combining them directly).
  - Introduces a novel Cyclic Positional Encoding (CPE) approach to better reflect cyclic route structures, ensuring adjacency and circularity are properly modeled.
  - Employs a cross-aspect referential attention mechanism that lets each embedding stream (node vs. position) inform the other without merging them prematurely.
  - Implements a curriculum learning strategy within a Proximal Policy Optimization (PPO) training framework to improve the sample efficiency when training iterative improvement policies.

- **Methodology**
  - **Dual-Aspect Representation**:
    - Each node in the solution has two parallel embeddings: one for node features (coordinates, demands, etc.) and one for the position in the route (via CPE).
  - **DACT Encoder**:
    - Uses separate self-attention streams for node features and positions, preventing interference between these two data types.
    - A cross-aspect attention mechanism enhances each stream by referencing the attention weights from the other, enabling better synergy.
  - **DACT Decoder**:
    - Aggregates proposals from both embedding streams (multi-head attention) to form the final action distribution over possible local moves (e.g., 2-opt).
    - The policy selects node pairs to perform local search steps iteratively.
  - **RL Setup**:
    - Uses PPO to learn a policy that, at each step, picks a node pair for a pairwise local search operator. The local search modifies the solution, and the agent receives a reward equal to the reduction in tour length if an improvement is found.
    - A “curriculum learning” step re-initializes the policy with higher-quality solutions as training proceeds, mitigating high variance and improving efficiency.

- **Experiments and Results**
  - Tested on randomly generated TSP and CVRP instances of sizes 20, 50, and 100, and on standard benchmark sets (TSPLIB, CVRPLIB).
  - Compared against:
    - Classical solvers: LKH, OR-Tools.
    - Neural construction methods: AM-sampling, POMO, MDAM.
    - Neural improvement methods: Wu et al.’s Transformer, Neural-2-Opt, NLNS, CVAE-based hybrids.
  - Key findings:
    - **Solution Quality**: Outperforms previous Transformer-based improvement approaches and shows competitive or better performance than other neural and hybrid baselines (e.g., Neural-2-Opt, Wu et al.).
    - **Generalization**: The cyclic encoding significantly enhances the model’s ability to solve different instance sizes than those used in training. PE-based Transformers degrade substantially on out-of-distribution sizes, while CPE-based DACT remains robust.
    - **Performance vs. Step Limits**: As the number of improvement steps (T) increases, DACT reaches near-optimal solutions for TSP and outperforms many baselines for CVRP.  
    - **Run Time**: DACT is efficient on GPU, though specialized approaches like POMO can be faster for small T. Nonetheless, DACT’s advantage in generalization is highlighted as a practical upside.

- **Strengths, Weaknesses, and Limitations**
  - **Strengths**:
    - Novel embedding scheme (dual-aspect + CPE) provides better representation of routing solutions.
    - Effective iterative improvement policy that adapts via PPO.
    - Strong generalization performance to larger problems and across TSP/CVRP.
    - Curriculum learning helps reduce variance and speeds up training convergence.
  - **Weaknesses**:
    - Focuses on TSP and CVRP; extension to more complex VRP variants (e.g., time windows) is not covered.
    - Inference time can be longer than certain construction-based RL models if many improvement steps are needed.
    - Relies on a particular local move (2-opt primarily), so synergy with other operators remains untested in-depth.

- **Relevance to Deterministic VRP and ML**
  - Directly aligns with the quest for improved ML-based iterative search heuristics for deterministic VRPs.
  - Offers potential to serve as a flexible plug-in in classical metaheuristics, bridging advanced deep learning (Transformer, RL) with conventional local search.
  - Demonstrates that specialized positional encodings and separated representation streams may resolve the known limitations of standard Transformers in cyclical graph problems.

- **Implications for Further Research**
  - Opens avenues for combining cyclical encoding with advanced local operators or multi-operator frameworks.
  - The dual-aspect approach could inspire new multi-embedding or multi-view methods for other routing or graph-based optimization tasks (e.g., circular DNA modeling, or other cyclical data).
  - Curriculum learning combined with RL-based local search could be generalized to more VRP variants (time windows, multi-depot) to enhance performance.